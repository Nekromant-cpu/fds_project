{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-28T17:08:23.304084700Z",
     "start_time": "2024-11-28T17:08:14.846924800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Faker in c:\\users\\noah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (33.1.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: python-dateutil>=2.4 in c:\\users\\noah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Faker) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\noah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Faker) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\noah\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.4->Faker) (1.16.0)\n",
      "Collecting fake-useragent\n",
      "  Downloading fake_useragent-1.5.1-py3-none-any.whl.metadata (15 kB)\n",
      "Downloading fake_useragent-1.5.1-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: fake-useragent\n",
      "Successfully installed fake-useragent-1.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install Faker\n",
    "!pip install fake-useragent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from faker import Faker\n",
    "import csv\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "base_url = \"https://www.amazon.com/dp/\"\n",
    "\n",
    "\n",
    "# headers = {\n",
    "#           'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 13_1) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.1 Safari/605.1.15',\n",
    "#           'Accept-Language': 'da, en-gb, en',\n",
    "#           'Accept-Encoding': 'gzip, deflate, br',\n",
    "#           'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',\n",
    "#           'Referer': 'https://www.google.com/'\n",
    "#         }\n",
    "\n",
    "\n",
    "def get_soup_retry(url):\n",
    "    # fake = Faker()\n",
    "    # uag_random = fake.user_agent()\n",
    "    ua = UserAgent(browsers=['edge', 'chrome', 'firefox', 'safari'], platforms='pc')\n",
    "    uag_random = ua.random\n",
    "\n",
    "    header = {\n",
    "        'User-Agent': uag_random,\n",
    "        'Accept-Language': 'en-US,en;q=0.9'\n",
    "    }\n",
    "    isCaptcha = True\n",
    "    while isCaptcha:\n",
    "        #time.sleep(random.uniform(0.5, 1))\n",
    "        page = requests.get(url, headers=header)\n",
    "        if not page.status_code == 200:\n",
    "            print(f\"page status code error: {page.status_code}\")\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        if 'captcha' in str(soup):\n",
    "            uag_random = ua.random #fake.user_agent()\n",
    "            print(f'\\rBot has been detected... retrying ... use new identity: {uag_random} ', end='', flush=True)\n",
    "            continue\n",
    "        else:\n",
    "            print('Bot bypassed')\n",
    "            return soup, page.status_code\n",
    "\n",
    "\n",
    "def get_description(soup):\n",
    "    div_class_description = \"a-expander-content a-expander-partial-collapse-content\"\n",
    "    outer_div = soup.find('div', {'data-a-expander-name': 'book_description_expander'})\n",
    "    \n",
    "    if outer_div:\n",
    "        inner_div = outer_div.find('div', class_=div_class_description)\n",
    "        if inner_div:\n",
    "            inner_text = inner_div.get_text(strip=True, separator=' ')\n",
    "            return inner_text\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_new_values(url):\n",
    "    soup, status_code = get_soup_retry(url)\n",
    "    \n",
    "    description = get_description(soup)\n",
    "    if description is None:\n",
    "        print(f\"Description not found for url: {url}\")\n",
    "        description = \"\"\n",
    "    return {\"description\" : description, \"code\" : status_code}\n",
    "\n",
    "def get_asin(row):\n",
    "    asin = row[0]\n",
    "    img_name = row[1]\n",
    "    # fix \"761183272\",\"0761183272.jpg\" -> \"0761183272\",\"0761183272.jpg\"\n",
    "    if len(asin) < (len(img_name) - len(\".jpg\")) and (asin[0] != '0' and img_name[0] == '0'):\n",
    "        asin = \"0\" + asin\n",
    "    return asin\n",
    "    \n",
    "\n",
    "def process_csv_no_header(input_csv, output_csv, start_row, end_row, rnd = 0):\n",
    "    with open(input_csv, mode='r', encoding='utf-8', errors='ignore') as infile, open(output_csv, mode='w', encoding='utf-8', newline='') as outfile:\n",
    "        # Read input as plain rows\n",
    "        reader = csv.reader(infile, quotechar='\"')\n",
    "        writer = csv.writer(outfile, quotechar='\"', quoting=csv.QUOTE_MINIMAL) # make sure to correctly escape characters\n",
    "\n",
    "        reader_list = list(reader)\n",
    "        random_list = []\n",
    "        if rnd > 0:\n",
    "            number_rows = len(reader_list)\n",
    "            random_list = sorted([random.randint(0, number_rows - 1) for _ in range(rnd)])\n",
    "            # print(random_list)\n",
    "\n",
    "        for row_index, row in enumerate(reader_list):\n",
    "            # Process rows within the range\n",
    "            if (rnd > 0 and (row_index in random_list)) or (rnd == 0 and start_row <= row_index < end_row):\n",
    "                # print(row)\n",
    "                if len(row) >= 7:\n",
    "                    # Check if there is an 8th and 9th field for description and status_code\n",
    "                    if len(row) >= 9:\n",
    "                        description = row[7].strip()\n",
    "                        # Replace description only if empty\n",
    "                        if not description:\n",
    "                            asin = get_asin(row)  # Assuming ASIN is in the first column\n",
    "                            new_values = get_new_values(base_url + asin)\n",
    "                            row[7] = new_values[\"description\"]\n",
    "                            row[8] = new_values[\"code\"]\n",
    "                    else:\n",
    "                        # Add a new 8th and 9th field if not present\n",
    "                        asin = get_asin(row)  # Assuming ASIN is in the first column\n",
    "                        new_values = get_new_values(base_url + asin)\n",
    "                        row.append(new_values[\"description\"])\n",
    "                        row.append(new_values[\"code\"])\n",
    "            # Write the row to the output CSV\n",
    "            writer.writerow(row)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-03T14:26:54.667417500Z",
     "start_time": "2024-12-03T14:26:54.443839400Z"
    }
   },
   "id": "404df308dd846f86"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36 Trailer/93.3.3516.28 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:123.0) Gecko/20100101 Firefox/123.0 Bot bypassed\n",
      "Description not found for url: https://www.amazon.com/dp/B00O80WC6I\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:123.0) Gecko/20100101 Firefox/123.0 Chrome/122.0.0.0 Safari/537.36 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 page status code error: 500\n",
      "Bot bypassed\n",
      "Description not found for url: https://www.amazon.com/dp/1578052084\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Bot bypassed\n",
      "page status code error: 500\n",
      "Bot bypassed\n",
      "Description not found for url: https://www.amazon.com/dp/1449468713\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 516.28 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:123.0) Gecko/20100101 Firefox/123.0 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36 Edg/121.0.0.0 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:123.0) Gecko/20100101 Firefox/123.0 Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Trailer/92.3.3357.27 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 GLS/100.10.9850.99  Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36 Edg/121.0.0.0 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 page status code error: 404\n",
      "Bot bypassed\n",
      "Description not found for url: https://www.amazon.com/dp/1452142068\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Agency/98.8.8188.80 Bot bypassed\n",
      "Description not found for url: https://www.amazon.com/dp/B00O80WC7C\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36 Agency/98.8.8175.80 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 516.28 Bot bypassed\n",
      "Description not found for url: https://www.amazon.com/dp/B00O80WC72\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (X11; Ubuntu; Linux x86_64) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15 6 Edg/121.0.0.0 516.28 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Unique/97.7.7239.70 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:123.0) Gecko/20100101 Firefox/123.0 Config/91.2.2121.13 ari/537.36 Edg/121.0.0.0 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Viewer/99.9.9009.89 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 page status code error: 404\n",
      "Bot bypassed\n",
      "Description not found for url: https://www.amazon.com/dp/162905576X\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 DuckDuckGo/7 Safari/605.1.15 /100.10.9850.99 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 GLS/100.10.9850.99 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36 Config/92.2.2788.20 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36 Edg/121.0.0.0 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36 15 /121.0.0.0 Unique/97.7.7286.70 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:123.0) Gecko/20100101 Firefox/123.0 Chrome/122.0.0.0 Safari/537.36 Edg/121.0.0.0 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 88.20 Bot bypassed\n",
      "Description not found for url: https://www.amazon.com/dp/B00O80WCEK\n",
      "Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Unique/97.7.7239.70 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Trailer/93.3.3695.30 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36 Edg/121.0.0.0 AtContent/95.5.5392.49 Bot bypassed\n",
      "Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 AtContent/95.5.5392.49 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Bot bypassed\n",
      "Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Unique/97.7.7239.70  9 page status code error: 404\n",
      "Bot bypassed\n",
      "Description not found for url: https://www.amazon.com/dp/145214141X\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Unique/97.7.7239.70  Bot bypassed\n",
      "Description not found for url: https://www.amazon.com/dp/B00O80WBZA\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:123.0) Gecko/20100101 Firefox/123.0 Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Bot bypassed\n",
      "Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:123.0) Gecko/20100101 Firefox/123.0 Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Bot bypassed\n",
      "Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (X11; Ubuntu; Linux x86_64) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15 6 Edg/121.0.0.0 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36 Edg/121.0.0.0 Herring/95.1.1930.31 Bot bypassed\n",
      "Description not found for url: https://www.amazon.com/dp/1629054321\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Unique/97.7.7239.70 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 GLS/100.10.9979.100 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Trailer/92.3.3357.27 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Bot bypassed\n",
      "Description not found for url: https://www.amazon.com/dp/B00O80WCHC\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Herring/95.1.1930.31 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 GLS/100.10.9415.94 .49 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:123.0) Gecko/20100101 Firefox/123.0 Chrome/122.0.0.0 Safari/537.36 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15 1.0.0.0 Trailer/93.3.3695.30 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (X11; Ubuntu; Linux x86_64) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15 6 Edg/121.0.0.0 AtContent/95.5.5392.49 Bot bypassed\n",
      "page status code error: 404\n",
      "Bot bypassed\n",
      "Description not found for url: https://www.amazon.com/dp/1629052183\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:123.0) Gecko/20100101 Firefox/123.0 Config/92.2.7601.2 fari/537.36 Edg/121.0.0.0 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Trailer/92.3.3357.27 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 DuckDuckGo/7 Safari/605.1.15 20 /97.7.7286.70 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Trailer/93.3.3695.30 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 AtContent/95.5.5392.49 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Herring/95.1.1930.31 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Unique/97.7.7286.70 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36 1.0.0.0 Bot bypassed\n",
      "Bot bypassed\n",
      "Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (X11; Ubuntu; Linux x86_64) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15 6 Edg/121.0.0.0 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:123.0) Gecko/20100101 Firefox/123.0 Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 GLS/100.10.9415.94 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 GLS/100.10.9415.94  Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Trailer/93.3.3695.30 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 GLS/100.10.9850.99  Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 15 que/97.7.7239.70 Bot bypassed\n",
      "Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:123.0) Gecko/20100101 Firefox/123.0 Config/91.2.2121.13 ari/537.36 Edg/121.0.0.0 Bot bypassed\n",
      "Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36 Edg/121.0.0.0 Bot bypassed\n",
      "Bot bypassed\n",
      "Bot bypassed\n",
      "Description not found for url: https://www.amazon.com/dp/1890931950\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Unique/97.7.7286.70 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 AtContent/95.5.5392.49 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:123.0) Gecko/20100101 Firefox/123.0 Bot bypassed\n",
      "Bot has been detected... retrying ... use new identity: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0 Trailer/92.3.3357.27 Bot bypassed\n"
     ]
    }
   ],
   "source": [
    "input_csv_path = \"book32-listing.csv\"\n",
    "output_csv_path = \"book32-listing_0_100.csv\"\n",
    "\n",
    "# Specify range of rows to process (e.g., rows 0–10)\n",
    "process_csv_no_header(input_csv_path, output_csv_path, start_row=0, end_row=100, rnd=0)\n",
    "# if rnd value is set and > 0 the values of start_row and end_row are not considered, we draw rnd rows from the csv file and scrape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-03T14:32:40.220740600Z",
     "start_time": "2024-12-03T14:26:54.634844600Z"
    }
   },
   "id": "8719b509b1cc3f3f"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from faker import Faker\n",
    "import csv\n",
    "from fake_useragent import UserAgent\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from threading import Lock\n",
    "from tqdm import tqdm # progress bar\n",
    "\n",
    "base_url = \"https://www.amazon.com/dp/\"\n",
    "lock = Lock()  # Ensures thread-safe writing to the CSV file\n",
    "description_counter = 0  # Global counter for descriptions found\n",
    "\n",
    "def get_soup_retry(url):\n",
    "    ua = UserAgent(browsers=['edge', 'chrome', 'firefox', 'safari'], platforms='pc')\n",
    "    uag_random = ua.random\n",
    "    header = {\n",
    "        'User-Agent': uag_random,\n",
    "        'Accept-Language': 'en-US,en;q=0.9'\n",
    "    }\n",
    "    isCaptcha = True\n",
    "    while isCaptcha:\n",
    "        page = requests.get(url, headers=header)\n",
    "        # if not page.status_code == 200:\n",
    "        #     print(f\"Page status code error: {page.status_code}\")\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        if 'captcha' in str(soup):\n",
    "            uag_random = ua.random\n",
    "            # print(f'\\rBot detected... retrying with new identity: {uag_random} ', end='', flush=True)\n",
    "            continue\n",
    "        else:\n",
    "            # print('Bot bypassed')\n",
    "            return soup, page.status_code\n",
    "\n",
    "def get_description(soup):\n",
    "    div_class_description = \"a-expander-content a-expander-partial-collapse-content\"\n",
    "    outer_div = soup.find('div', {'data-a-expander-name': 'book_description_expander'})\n",
    "    if outer_div:\n",
    "        inner_div = outer_div.find('div', class_=div_class_description)\n",
    "        if inner_div:\n",
    "            return inner_div.get_text(strip=True, separator=' ')\n",
    "    return None\n",
    "\n",
    "def get_new_values(url):\n",
    "    soup, status_code = get_soup_retry(url)\n",
    "    description = get_description(soup) or \"\"\n",
    "    return {\"description\": description, \"code\": status_code}\n",
    "\n",
    "def get_asin(row):\n",
    "    asin = row[0]\n",
    "    img_name = row[1]\n",
    "    if len(asin) < (len(img_name) - len(\".jpg\")) and (asin[0] != '0' and img_name[0] == '0'):\n",
    "        asin = \"0\" + asin\n",
    "    return asin\n",
    "\n",
    "def process_row(row, writer, progress_bar):\n",
    "    global description_counter\n",
    "    if len(row) >= 7:\n",
    "        if len(row) >= 9:\n",
    "            if not row[7].strip():  # Replace empty description\n",
    "                asin = get_asin(row)\n",
    "                new_values = get_new_values(base_url + asin)\n",
    "                row[7] = new_values[\"description\"]\n",
    "                row[8] = new_values[\"code\"]\n",
    "                if new_values[\"description\"]:\n",
    "                    with lock:\n",
    "                        description_counter += 1\n",
    "        else:\n",
    "            asin = get_asin(row)\n",
    "            new_values = get_new_values(base_url + asin)\n",
    "            row.append(new_values[\"description\"])\n",
    "            row.append(new_values[\"code\"])\n",
    "            if new_values[\"description\"]:\n",
    "                with lock:\n",
    "                    description_counter += 1\n",
    "        # Write row with a lock to avoid race conditions\n",
    "        with lock:\n",
    "            writer.writerow(row)\n",
    "    progress_bar.update(1)\n",
    "\n",
    "def process_csv_parallel(input_csv, output_csv, start_row, end_row, rnd=0, max_workers=5):\n",
    "    global description_counter\n",
    "    description_counter = 0 # reset\n",
    "    with open(input_csv, mode='r', encoding='utf-8', errors='ignore') as infile, \\\n",
    "         open(output_csv, mode='w', encoding='utf-8', newline='') as outfile:\n",
    "        reader = csv.reader(infile, quotechar='\"')\n",
    "        writer = csv.writer(outfile, quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "        reader_list = list(reader)\n",
    "        random_list = []\n",
    "        if rnd > 0:\n",
    "            number_rows = len(reader_list)\n",
    "            random_list = sorted([random.randint(0, number_rows - 1) for _ in range(rnd)])\n",
    "\n",
    "        total_rows = (end_row - start_row) if rnd == 0 else len(random_list)\n",
    "        with tqdm(total=total_rows, desc=\"Processing Rows\") as progress_bar:\n",
    "            with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "                futures = []\n",
    "                for row_index, row in enumerate(reader_list):\n",
    "                    if (rnd > 0 and row_index in random_list) or (rnd == 0 and start_row <= row_index < end_row):\n",
    "                        futures.append(executor.submit(process_row, row, writer, progress_bar))\n",
    "    \n",
    "                for future in futures:\n",
    "                    future.result()  # Ensure all tasks complete before exiting\n",
    "    print(f\"\\nDescriptions found: {description_counter} / {end_row - start_row}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-04T10:49:21.154577300Z",
     "start_time": "2024-12-04T10:49:20.412183700Z"
    }
   },
   "id": "4e469c85e2b61938"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows: 100%|██████████| 700/700 [04:29<00:00,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descriptions found: 4 / 700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_input_csv_path = \"book30-listing-train.csv\"\n",
    "new_output_csv_path = \"book30-listing-train_0_100.csv\"\n",
    "\n",
    "# Specify range of rows to process (e.g., rows 0–10)\n",
    "process_csv_parallel(new_input_csv_path, new_output_csv_path, start_row=0, end_row=700, rnd=0, max_workers=4)\n",
    "# if rnd value is set and > 0 the values of start_row and end_row are not considered, we draw rnd rows from the csv file and scrape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-04T11:09:02.360514100Z",
     "start_time": "2024-12-04T11:04:32.364900900Z"
    }
   },
   "id": "1e20fcd64539ebf6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#concatenate csv files"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6cc490ef35d1ad03"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Define the pattern for your CSV files\n",
    "file_pattern = \"data/book_descriptions_test_*.csv\"\n",
    "\n",
    "# Sort files by the numeric range in their names\n",
    "csv_files = sorted(glob.glob(file_pattern), key=lambda x: int(x.split('_')[-1].split('.')[0].split('-')[0]))\n",
    "# print(csv_files)\n",
    "\n",
    "# Initialize an empty list to hold the dataframes\n",
    "dataframes = []\n",
    "\n",
    "\n",
    "for i, file in enumerate(csv_files):\n",
    "    if i == 0:\n",
    "        # Read the first file including the header, handle quotes and line breaks\n",
    "        df = pd.read_csv(file, quotechar='\"', skip_blank_lines=True, engine=\"python\")\n",
    "    else:\n",
    "        # Read subsequent files, skipping the first line (header)\n",
    "        df = pd.read_csv(file, skiprows=1, quotechar='\"', skip_blank_lines=True, engine=\"python\")\n",
    "    \n",
    "    # Ensure numeric columns like \"200\" remain integers and drop empty trailing columns\n",
    "    df = df.convert_dtypes()  # Infer correct column types\n",
    "    df = df.dropna(how=\"all\")  # Drop rows where all elements are NaN\n",
    "\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Save the merged DataFrame to a single CSV file\n",
    "merged_df.to_csv(\"data/book_description_test_complete.csv\", index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-04T23:16:47.234331900Z",
     "start_time": "2024-12-04T23:16:45.793221500Z"
    }
   },
   "id": "4e0cfa18cabb017b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# clean text"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c66b81e4cb099f8"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned CSV has been saved to cleaned_output_1.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "# Function to clean control characters from a string\n",
    "def remove_control_characters(text):\n",
    "    # Remove all control characters (non-printable characters)\n",
    "    # return re.sub(r'[^\\x20-\\x7E\\n\\r\\t]', '', text)  # Keep spaces, printable characters, newlines, and tabs\n",
    "    return re.sub(r'[\\x00-\\x1F\\x7F]', '', text)  # Remove ASCII control characters\n",
    "\n",
    "# Function to clean CSV file\n",
    "def clean_csv(input_file, output_file):\n",
    "    with open(input_file, 'r', encoding='utf-8', errors='ignore') as infile, \\\n",
    "         open(output_file, 'w', newline='', encoding='utf-8') as outfile:\n",
    "        \n",
    "        reader = csv.reader(infile)\n",
    "        writer = csv.writer(outfile)\n",
    "        \n",
    "        for row in reader:\n",
    "            # Clean each cell in the row\n",
    "            cleaned_row = [remove_control_characters(cell) for cell in row]\n",
    "            writer.writerow(cleaned_row)\n",
    "    \n",
    "    print(f\"Cleaned CSV has been saved to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "input_file = 'book30-listing-test.csv'  # Replace with your input CSV file\n",
    "output_file = 'cleaned_output_1.csv'  # Replace with your desired output CSV file\n",
    "clean_csv(input_file, output_file)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-05T19:34:33.172532300Z",
     "start_time": "2024-12-05T19:34:33.061342800Z"
    }
   },
   "id": "24bc9056005f5be6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# merge csv files"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "732e08a13a62290e"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data written to ../data/full_data/book_descriptions_train_full.csv\n",
      "Unmatched IDs written to unmatched_ids_test2.txt\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# File paths\n",
    "file1 = 'book30-listing-train.csv'  # First file path\n",
    "file2 = 'data/book_descriptions_train.csv'  # Second file path\n",
    "output_file = '../data/full_data/book_descriptions_train_full.csv'  # Output file path\n",
    "unmatched_ids_file = 'unmatched_ids_test2.txt'  # File to save unmatched IDs\n",
    "\n",
    "# Column names for both files\n",
    "file1_headers = ['id', 'img_name', 'img_url', 'title', 'author', 'category_id', 'category']\n",
    "file2_headers = ['id', 'description', 'status_code']\n",
    "\n",
    "# Read the second file into a dictionary for quick lookup\n",
    "second_file_data = {}\n",
    "with open(file2, 'r', encoding='utf-8') as f2:  # Use utf-8 encoding\n",
    "    reader = csv.reader(f2)\n",
    "    for row in reader:\n",
    "        row_data = dict(zip(file2_headers, row))\n",
    "        second_file_data[row_data['id']] = row_data\n",
    "\n",
    "# Open the first file and merge with the second file data\n",
    "unmatched_ids = []\n",
    "with open(file1, 'r', encoding='utf-8') as f1, open(output_file, 'w', newline='', encoding='utf-8') as out_file:\n",
    "    reader = csv.reader(f1)\n",
    "    writer = csv.writer(out_file)\n",
    "    \n",
    "    # Write the header for the output file\n",
    "    output_headers = file1_headers + ['description', 'status_code']\n",
    "    writer.writerow(output_headers)\n",
    "    \n",
    "    for row in reader:\n",
    "        row_data = dict(zip(file1_headers, row))\n",
    "        id_ = row_data['id']\n",
    "        img_name = row_data['img_name']\n",
    "        if (len(img_name) - len(\".jpg\")) > len(id_) and img_name[0] == \"0\":\n",
    "            id_ = img_name[:-4]\n",
    "            row_data.update({'id': id_})\n",
    "        if id_ in second_file_data:\n",
    "            # Merge rows\n",
    "            row_data.update(second_file_data[id_])\n",
    "        else:\n",
    "            # Record unmatched ID\n",
    "            unmatched_ids.append(id_)\n",
    "            row_data.update({'description': '', 'status_code': ''})\n",
    "        \n",
    "        # Write the merged row\n",
    "        writer.writerow([row_data[col] for col in output_headers])\n",
    "\n",
    "# Write unmatched IDs to a text file\n",
    "# with open(unmatched_ids_file, 'w', encoding='utf-8') as unmatched_file:\n",
    "#     for id_ in unmatched_ids:\n",
    "#         unmatched_file.write(f\"{id_}\\n\")\n",
    "\n",
    "print(f\"Merged data written to {output_file}\")\n",
    "print(f\"Unmatched IDs written to {unmatched_ids_file}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T13:36:08.635401600Z",
     "start_time": "2024-12-08T13:35:59.358036500Z"
    }
   },
   "id": "d7d582d6ae73b2d2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get some statistics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8337013442964ed"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics have been written to ../data/stats/book_descriptions_test_balanced.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def gather_statistics(input_file, output_file):\n",
    "    # Load the CSV file into a Pandas DataFrame\n",
    "    df = pd.read_csv(input_file, encoding='utf-8')\n",
    "    \n",
    "    # Total number of entries\n",
    "    total_entries = len(df)\n",
    "    \n",
    "    # Entries with non-empty description\n",
    "    entries_with_description = len(df[df['description'].notna() & (df['description'] != '')])\n",
    "    \n",
    "    # Number of entries per category\n",
    "    category_counts = df['category'].value_counts()\n",
    "    \n",
    "    # Number of entries with non-empty description per category\n",
    "    category_with_description_counts = df[df['description'].notna() & (df['description'] != '')]['category'].value_counts()\n",
    "    \n",
    "    # Find the category with the least entries with non-empty description\n",
    "    least_entries_category = category_with_description_counts.idxmin()\n",
    "    least_entries_count = category_with_description_counts.min()\n",
    "    \n",
    "    # Prepare the results in a string format for writing to file\n",
    "    output = []\n",
    "    output.append(f\"Total entries: {total_entries}\\n\")\n",
    "    output.append(f\"Entries with non-empty description: {entries_with_description}\\n\")\n",
    "    \n",
    "    output.append(\"Entries per category:\\n\")\n",
    "    output.append(category_counts.to_string())\n",
    "    \n",
    "    output.append(\"\\nEntries with non-empty description per category:\\n\")\n",
    "    output.append(category_with_description_counts.to_string())\n",
    "    \n",
    "    output.append(f\"\\nCategory with least entries with non-empty description: {least_entries_category}\")\n",
    "    output.append(f\"Number of entries: {least_entries_count}\")\n",
    "    \n",
    "    # Write the statistics to the output file\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"\\n\".join(output))\n",
    "    \n",
    "    print(f\"Statistics have been written to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "input_file = '../data/full_data/book_descriptions_test_balanced.csv'  # Replace with your merged CSV file\n",
    "output_file = '../data/stats/book_descriptions_test_balanced.txt'  # Replace with your desired output text file\n",
    "gather_statistics(input_file, output_file)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T13:42:08.907764300Z",
     "start_time": "2024-12-08T13:42:08.783146900Z"
    }
   },
   "id": "d50d2069144181e4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Balance dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aab749d8ebeebaa"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category with the least non-empty descriptions has 164 entries.\n",
      "Cleaned and balanced dataset saved to ../data/full_data/book_descriptions_test_balanced.csv\n",
      "Final dataset contains 4756 entries.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_and_balance_dataset(input_file, output_file):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(input_file, encoding='utf-8')\n",
    "    \n",
    "    # Step 1: Remove entries with category_id = 3\n",
    "    df = df[df['category_id'] != 3]\n",
    "    \n",
    "    # Step 2: Decrement category_id by 1 for all category_id >= 4\n",
    "    df['category_id'] = df['category_id'].apply(lambda x: x - 1 if x >= 4 else x)\n",
    "    \n",
    "    # Step 3: Filter out rows without descriptions (keep only rows with non-empty descriptions)\n",
    "    df['description'] = df['description'].fillna('')  # Replace NaN descriptions with empty strings\n",
    "    df = df[df['description'].apply(lambda x: x.strip() != '')]  # Keep only rows with non-empty descriptions\n",
    "    \n",
    "    # Step 4: Count non-empty descriptions for each category\n",
    "    category_description_counts = df['category_id'].value_counts()\n",
    "    \n",
    "    # Step 5: Find the smallest number of non-empty descriptions across all categories\n",
    "    min_descriptions = category_description_counts.min()\n",
    "    print(f\"Category with the least non-empty descriptions has {min_descriptions} entries.\")\n",
    "    \n",
    "    # Step 6: Balance the dataset by randomly sampling entries from each category\n",
    "    balanced_dfs = []\n",
    "    for category_id, group in df.groupby('category_id'):\n",
    "        # Randomly sample from the rows to match `min_descriptions`\n",
    "        sampled_group = group.sample(n=min_descriptions, random_state=42)\n",
    "        balanced_dfs.append(sampled_group)\n",
    "    \n",
    "    # Concatenate all balanced dataframes\n",
    "    balanced_df = pd.concat(balanced_dfs)\n",
    "    \n",
    "    # Step 7: Save the cleaned and balanced dataset to a new CSV file\n",
    "    balanced_df.to_csv(output_file, index=False, encoding='utf-8')\n",
    "    \n",
    "    # Output statistics\n",
    "    print(f\"Cleaned and balanced dataset saved to {output_file}\")\n",
    "    print(f\"Final dataset contains {len(balanced_df)} entries.\")\n",
    "\n",
    "# Example usage\n",
    "input_file = '../data/full_data/book_descriptions_test_full.csv'  # Replace with your input CSV file\n",
    "output_file = '../data/full_data/book_descriptions_test_balanced.csv'  # Replace with your desired output CSV file\n",
    "clean_and_balance_dataset(input_file, output_file)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T13:41:42.560090500Z",
     "start_time": "2024-12-08T13:41:42.294219900Z"
    }
   },
   "id": "ae5727c9da010040"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create train and test dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d41656a181160ba7"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset saved to ../data/book_descriptions_train.csv\n",
      "Total entries in the training dataset: 41470\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def prepare_training_dataset(input_file, output_file):\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(input_file, encoding='utf-8')\n",
    "    \n",
    "    # Step 1: Select only the relevant columns\n",
    "    df = df[['img_name', 'description', 'category_id']]\n",
    "    \n",
    "    # Step 2: Limit the description to 500 characters\n",
    "    # df['description'] = df['description'].apply(lambda x: x[:500] if isinstance(x, str) else x)\n",
    "    \n",
    "    # Step 3: Shuffle the dataset randomly\n",
    "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    # Step 4: Save the simplified dataset to a new CSV file\n",
    "    df.to_csv(output_file, index=False, encoding='utf-8')\n",
    "    \n",
    "    print(f\"Training dataset saved to {output_file}\")\n",
    "    print(f\"Total entries in the training dataset: {len(df)}\")\n",
    "\n",
    "# Example usage\n",
    "input_file = '../data/full_data/book_descriptions_train_balanced.csv'  # Replace with your balanced dataset file\n",
    "output_file = '../data/book_descriptions_train.csv'  # Replace with your desired output file\n",
    "prepare_training_dataset(input_file, output_file)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T13:43:46.332993100Z",
     "start_time": "2024-12-08T13:43:42.494391Z"
    }
   },
   "id": "cd1484796b556fcb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check for missing img files"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd6b5f5e2b2c4f70"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def find_missing_images(folder_path, csv_file_path):\n",
    "    # Step 1: Get all file names in the folder\n",
    "    folder_files = set(os.listdir(folder_path))\n",
    "    \n",
    "    # Step 2: Load the CSV file and extract the img_name column\n",
    "    df = pd.read_csv(csv_file_path, encoding='utf-8')\n",
    "    csv_images = set(df['img_name'])\n",
    "    \n",
    "    # Step 3: Find img_names in the CSV that are not in the folder\n",
    "    missing_images = csv_images - folder_files\n",
    "    \n",
    "    # Step 4: Print the missing img_names\n",
    "    if missing_images:\n",
    "        print(\"Missing images:\")\n",
    "        for img_name in missing_images:\n",
    "            print(img_name)\n",
    "    else:\n",
    "        print(\"All images in the CSV are present in the folder.\")\n",
    "\n",
    "# Example usage\n",
    "folder_path = '../data/images'  # Replace with the path to your folder\n",
    "csv_file_path = '../data/book_descriptions_test.csv'   # Replace with the path to your CSV file\n",
    "find_missing_images(folder_path, csv_file_path)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "250fae3b05ab130a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# remove image files that we are not using"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "724aacf770ca009"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def remove_unmatched_images(folder_path, csv_file1, csv_file2):\n",
    "    # Step 1: Load both CSV files\n",
    "    df1 = pd.read_csv(csv_file1, encoding='utf-8')\n",
    "    df2 = pd.read_csv(csv_file2, encoding='utf-8')\n",
    "    \n",
    "    # Step 2: Get the set of all valid image names from both CSVs\n",
    "    valid_img_names = set(pd.concat([df1['img_name'], df2['img_name']]).dropna())\n",
    "    \n",
    "    # Step 3: Iterate through files in the folder and remove unmatched ones\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name not in valid_img_names:\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            os.remove(file_path)\n",
    "            print(f\"Removed: {file_name}\")\n",
    "    \n",
    "    print(\"Cleanup complete. All unmatched files have been removed.\")\n",
    "\n",
    "# Example usage\n",
    "folder_path = '../data/images'    # Replace with your folder path\n",
    "csv_file1 = '../data/book_descriptions_test.csv'          # Replace with the path to your first CSV file\n",
    "csv_file2 = '../data/book_descriptions_train.csv'          # Replace with the path to your second CSV file\n",
    "remove_unmatched_images(folder_path, csv_file1, csv_file2)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "294ab5272361f612"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
